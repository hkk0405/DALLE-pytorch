{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import sqrt\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.optim.lr_scheduler import ExponentialLR, CosineAnnealingLR\n",
    "\n",
    "# vision imports\n",
    "\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "# dalle classes\n",
    "\n",
    "from dalle_pytorch import DiscreteVAE\n",
    "\n",
    "# import osgmlg\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "IMAGE_PATH = '/disk/nvme2/report_images/2006-06-28_기업_미래에셋증권_황상연,신지원_LG석유화학(012990)_145795'\n",
    "\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 5e-4\n",
    "LR_DECAY_RATE = 0.99999\n",
    "\n",
    "NUM_TOKENS = 8192\n",
    "NUM_LAYERS = 3\n",
    "NUM_RESNET_BLOCKS = 3\n",
    "SMOOTH_L1_LOSS = False\n",
    "EMB_DIM = 512\n",
    "HID_DIM = 256\n",
    "# KL_LOSS_WEIGHT = 6.6\n",
    "\n",
    "STARTING_TEMP = 1.\n",
    "TEMP_MIN = 1e-10\n",
    "ANNEAL_RATE = 1e-3\n",
    "\n",
    "NUM_IMAGES_SAVE = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "\n",
    "ds = ImageFolder(\n",
    "    IMAGE_PATH,\n",
    "    T.Compose([\n",
    "        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "        T.Resize(IMAGE_SIZE),\n",
    "        T.CenterCrop(IMAGE_SIZE),\n",
    "        T.ToTensor()\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_params = dict(\n",
    "    image_size = IMAGE_SIZE,\n",
    "    num_layers = NUM_LAYERS,\n",
    "    num_tokens = NUM_TOKENS,\n",
    "    codebook_dim = EMB_DIM,\n",
    "    hidden_dim   = HID_DIM,\n",
    "    num_resnet_blocks = NUM_RESNET_BLOCKS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = DiscreteVAE(\n",
    "    **vae_params,\n",
    "    smooth_l1_loss = SMOOTH_L1_LOSS,\n",
    "    # kl_div_loss_weight = KL_LOSS_WEIGHT\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(ds) > 0, 'folder does not contain any images'\n",
    "print(f'{len(ds)} images found for training')\n",
    "\n",
    "# def save_model(path):\n",
    "#     save_obj = {\n",
    "#         'hparams': vae_params,\n",
    "#         'weights': vae.state_dict()\n",
    "#     }\n",
    "\n",
    "#     torch.save(save_obj, path)\n",
    "\n",
    "# optimizer\n",
    "\n",
    "opt = Adam(vae.parameters(), lr = LEARNING_RATE)\n",
    "# opt = AdamW(vae.parameters(), lr=LEARNING_RATE, betas=(0.9, 0.999), eps=1e-8, weight_decay=1e-4)\n",
    "sched = ExponentialLR(optimizer = opt, gamma = LR_DECAY_RATE)\n",
    "# sched = CosineAnnealingLR(optimizer=opt,)\n",
    "\n",
    "# weights & biases experiment tracking\n",
    "\n",
    "import wandb\n",
    "\n",
    "model_config = dict(\n",
    "    num_tokens = NUM_TOKENS,\n",
    "    smooth_l1_loss = SMOOTH_L1_LOSS,\n",
    "    num_resnet_blocks = NUM_RESNET_BLOCKS,\n",
    "    # kl_loss_weight = KL_LOSS_WEIGHT\n",
    ")\n",
    "\n",
    "run = wandb.init(\n",
    "    project = 'dalle_train_vae_test',\n",
    "    job_type = 'train_model',\n",
    "    config = model_config\n",
    ")\n",
    "\n",
    "# starting temperature\n",
    "\n",
    "global_step = 0\n",
    "temp = STARTING_TEMP\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (images, _) in enumerate(dl):\n",
    "        images = images.cuda()\n",
    "\n",
    "        loss, recons = vae(\n",
    "            images,\n",
    "            return_loss = True,\n",
    "            return_recons = True,\n",
    "            temp = temp\n",
    "        )\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        logs = {}\n",
    "\n",
    "        if i % 1 == 0:\n",
    "            k = NUM_IMAGES_SAVE\n",
    "\n",
    "            with torch.no_grad():\n",
    "                codes = vae.get_codebook_indices(images[:k])\n",
    "                hard_recons = vae.decode(codes)\n",
    "\n",
    "            images, recons = map(lambda t: t[:k], (images, recons))\n",
    "            images, recons, hard_recons, codes = map(lambda t: t.detach().cpu(), (images, recons, hard_recons, codes))\n",
    "            images, recons, hard_recons = map(lambda t: make_grid(t.float(), nrow = int(sqrt(k)), normalize = True, range = (-1, 1)), (images, recons, hard_recons))\n",
    "\n",
    "            logs = {\n",
    "                **logs,\n",
    "                'sample images':        wandb.Image(images, caption = 'original images'),\n",
    "                'reconstructions':      wandb.Image(recons, caption = 'reconstructions'),\n",
    "                'hard reconstructions': wandb.Image(hard_recons, caption = 'hard reconstructions'),\n",
    "                'codebook_indices':     wandb.Histogram(codes),\n",
    "                'temperature':          temp\n",
    "            }\n",
    "\n",
    "            # save_model(f'./vae.pt')\n",
    "            # wandb.save('./vae.pt')\n",
    "\n",
    "            # temperature anneal\n",
    "\n",
    "            temp = max(temp * math.exp(-ANNEAL_RATE * global_step), TEMP_MIN)\n",
    "\n",
    "            # lr decay\n",
    "\n",
    "            sched.step()\n",
    "\n",
    "        if i % 1 == 0:\n",
    "            lr = sched.get_last_lr()[0]\n",
    "            print(epoch, i, f'lr - {lr:6f} loss - {loss.item()}')\n",
    "\n",
    "            logs = {\n",
    "                **logs,\n",
    "                'epoch': epoch,\n",
    "                'iter': i,\n",
    "                'loss': loss.item(),\n",
    "                'lr': lr\n",
    "            }\n",
    "\n",
    "        wandb.log(logs)\n",
    "        global_step += 1\n",
    "\n",
    "    # save trained model to wandb as an artifact every epoch's end\n",
    "\n",
    "    # model_artifact = wandb.Artifact('trained-vae', type = 'model', metadata = dict(model_config))\n",
    "    # model_artifact.add_file('vae.pt')\n",
    "    # run.log_artifact(model_artifact)\n",
    "\n",
    "# save final vae and cleanup\n",
    "\n",
    "# save_model('./vae-final.pt')\n",
    "# wandb.save('./vae-final.pt')\n",
    "\n",
    "# model_artifact = wandb.Artifact('trained-vae', type = 'model', metadata = dict(model_config))\n",
    "# model_artifact.add_file('vae-final.pt')\n",
    "# run.log_artifact(model_artifact)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dl:\n",
    "    print(i[0].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = vae(i[0], return_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2, sqrt\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from axial_positional_embedding import AxialPositionalEmbedding\n",
    "from einops import rearrange\n",
    "\n",
    "from dalle_pytorch import distributed_utils\n",
    "from dalle_pytorch.vae import OpenAIDiscreteVAE, VQGanVAE\n",
    "from dalle_pytorch.transformer import Transformer, DivideMax\n",
    "\n",
    "codebook = nn.Embedding(8192, 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_chans = [196] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_chans = list(reversed(enc_chans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_chans = [3, *enc_chans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_chans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_init_chan = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_chans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vae = torch.load('/dalle/vae-final-ds-cp/global_step121623_reports_7M/mp_rank_00_model_states.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vae.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_vae['hparams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvae = DiscreteVAE(num_layers=4, codebook_dim=768, hidden_dim=256, num_resnet_blocks=2, num_tokens=8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvae.load_state_dict(custom_vae['module'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dvae.get_codebook_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
